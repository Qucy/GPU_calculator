{
  "gpus": [
    {
      "name": "NVIDIA A100",
      "vendor": "NVIDIA",
      "architecture": "Ampere (GA100)",
      "process_node": "TSMC 7 nm",
      "cuda_cores": 6912,
      "tensor_cores": "3rd Gen (312)",
      "rt_cores": "None",
      "fp32_tflops": 19.5,
      "fp16_tflops": 312,
      "int8_tops": 624,
      "memory_gb": "40 / 80",
      "memory_type": "HBM2e",
      "memory_bandwidth_tbps": 2.0,
      "nvlink_bandwidth_gbs": 600,
      "pcie_generation": "4.0",
      "tdp_w": "250 (PCIe) / 400 (SXM4)",
      "price_usd": 30000,
      "price_rmb": 210000,
      "release_year": 2020,
      "mig_support": "Yes (up to 7 instances)",
      "transformer_engine": "No",
      "notes": "FP16/INT8 values include sparsity; up to 7 MIG instances; NVLink Gen3 600 GB/s."
    },
    {
      "name": "NVIDIA H100",
      "vendor": "NVIDIA",
      "architecture": "Hopper (GH100) with Transformer Engine",
      "process_node": "TSMC 4N (5 nm class)",
      "cuda_cores": 16896,
      "tensor_cores": "4th Gen (528)",
      "rt_cores": "None",
      "fp32_tflops": 67,
      "fp16_tflops": 1979,
      "int8_tops": 3958,
      "memory_gb": 80,
      "memory_type": "HBM3 (SXM) / HBM2e (PCIe)",
      "memory_bandwidth_tbps": 3.35,
      "nvlink_bandwidth_gbs": 900,
      "pcie_generation": "5.0",
      "tdp_w": "350-400 (PCIe) / 700 (SXM5)",
      "price_usd": "25000 - 40000",
      "price_rmb": null,
      "release_year": 2022,
      "mig_support": "Yes (up to 7 instances)",
      "transformer_engine": "Yes (with FP8 support)",
      "notes": "NVLink Gen4 (900 GB/s), Transformer Engine with FP8 support, 528 Tensor Cores."
    },
    {
      "name": "NVIDIA H200",
      "vendor": "NVIDIA",
      "architecture": "Hopper (GH100/Hopper 2)",
      "process_node": "TSMC 4N (5 nm class)",
      "cuda_cores": 16896,
      "tensor_cores": "4th Gen (Enhanced)",
      "rt_cores": "None",
      "fp32_tflops": 67,
      "fp16_tflops": 1979,
      "int8_tops": 3958,
      "memory_gb": 141,
      "memory_type": "HBM3e",
      "memory_bandwidth_tbps": 4.8,
      "nvlink_bandwidth_gbs": 900,
      "pcie_generation": "5.0",
      "tdp_w": 700,
      "price_usd": 40000,
      "price_rmb": null,
      "release_year": 2024,
      "mig_support": "Yes (up to 7 instances, 16.5GB each)",
      "transformer_engine": "Yes (Enhanced FP8)",
      "notes": "2x faster LLM inference vs H100, improved energy efficiency, NVLink4 900 GB/s."
    },
    {
      "name": "NVIDIA H20",
      "vendor": "NVIDIA",
      "architecture": "Hopper (China-compliant)",
      "process_node": "TSMC 4N (5 nm class)",
      "cuda_cores": 16896,
      "tensor_cores": "4th Gen (Restricted)",
      "rt_cores": "None",
      "fp32_tflops": 44,
      "fp16_tflops": 148,
      "int8_tops": 296,
      "memory_gb": 96,
      "memory_type": "HBM3",
      "memory_bandwidth_tbps": 4.0,
      "nvlink_bandwidth_gbs": 400,
      "pcie_generation": "5.0",
      "tdp_w": 400,
      "price_usd": 12000,
      "price_rmb": 84000,
      "release_year": 2024,
      "mig_support": "Yes",
      "transformer_engine": "Yes (Limited)",
      "notes": "Designed for China market; lower interconnect bandwidth to meet export limits."
    },
    {
      "name": "NVIDIA L40S",
      "vendor": "NVIDIA",
      "architecture": "Ada Lovelace (AD102)",
      "process_node": "TSMC 5 nm",
      "cuda_cores": 18176,
      "tensor_cores": "4th Gen (568)",
      "rt_cores": "3rd Gen (142)",
      "fp32_tflops": 91.6,
      "fp16_tflops": 183.2,
      "int8_tops": 734.4,
      "memory_gb": 48,
      "memory_type": "GDDR6 ECC",
      "memory_bandwidth_tbps": 0.864,
      "nvlink_bandwidth_gbs": "None",
      "pcie_generation": "4.0",
      "tdp_w": 350,
      "price_usd": null,
      "price_rmb": null,
      "release_year": 2023,
      "mig_support": "No",
      "transformer_engine": "No",
      "notes": "No NVLink; PCIe Gen4; optimized for generative AI and RTX workloads."
    },
    {
      "name": "Biren BR100",
      "vendor": "Biren Technology",
      "architecture": "Bilin (BR100) MCM dual-die",
      "process_node": "TSMC 7 nm",
      "cuda_cores": "Not disclosed",
      "tensor_cores": "Proprietary T-cores",
      "rt_cores": "None",
      "fp32_tflops_vendor_peak": 256,
      "fp32_tflops_measured": 16,
      "fp16_tflops": 1024,
      "int8_tops": 2048,
      "memory_gb": 64,
      "memory_type": "HBM2e",
      "memory_bandwidth_tbps": 2.3,
      "nvlink_bandwidth_gbs": "B-Link 448 GB/s",
      "pcie_generation": "5.0 with CXL",
      "tdp_w": 550,
      "price_usd": null,
      "price_rmb": null,
      "release_year": 2022,
      "mig_support": "Yes (SVI - Secure Virtual Instance)",
      "transformer_engine": "No",
      "notes": "Dual-die (77B transistors total); proprietary B-Link interconnect (2.3 TB/s); 300 MB cache; claimed 2.6× A100 performance."
    },
    {
      "name": "Alibaba Pingtouge PPU",
      "vendor": "Alibaba Group (Pingtouge)",
      "architecture": "PPU Gen1",
      "process_node": "Domestic 7 nm (SMIC)",
      "cuda_cores": "Not disclosed",
      "tensor_cores": "Proprietary",
      "rt_cores": "None",
      "fp32_tflops": 120,
      "fp16_tflops": null,
      "int8_tops": 200,
      "memory_gb": 96,
      "memory_type": "HBM2e",
      "memory_bandwidth_tbps": 0.7,
      "nvlink_bandwidth_gbs": "Inter-chip 700 GB/s",
      "pcie_generation": "5.0 x15",
      "tdp_w": 400,
      "price_usd": null,
      "price_rmb": null,
      "release_year": 2024,
      "mig_support": "Unknown",
      "transformer_engine": "No",
      "notes": "700 GB/s inter-chip link; deployed at Alibaba Cloud (16,384 cards); competitive with NVIDIA H20."
    },
    {
      "name": "Baidu Kunlunxin K100",
      "vendor": "Baidu",
      "architecture": "Kunlunxin 1st Gen XPU-K",
      "process_node": "Samsung 14 nm",
      "cuda_cores": "Not disclosed",
      "tensor_cores": "Proprietary XPU cores",
      "rt_cores": "None",
      "fp32_tflops": 8,
      "fp16_tflops": 32,
      "int8_tops": 128,
      "memory_gb": 8,
      "memory_type": "HBM",
      "memory_bandwidth_tbps": 0.512,
      "nvlink_bandwidth_gbs": "None",
      "pcie_generation": "4.0 x8",
      "tdp_w": 75,
      "price_usd": null,
      "price_rmb": null,
      "release_year": 2018,
      "mig_support": "No",
      "transformer_engine": "No",
      "notes": "Edge-oriented AI accelerator; compact design; used for inference workloads."
    },
    {
      "name": "Baidu Kunlunxin K200",
      "vendor": "Baidu",
      "architecture": "Kunlunxin Gen1 XPU",
      "process_node": "Samsung 14 nm",
      "cuda_cores": "Not disclosed",
      "tensor_cores": "Proprietary XPU cores",
      "rt_cores": "None",
      "fp32_tflops": 16,
      "fp16_tflops": 64,
      "int8_tops": 256,
      "memory_gb": 16,
      "memory_type": "HBM2e",
      "memory_bandwidth_tbps": 0.512,
      "nvlink_bandwidth_gbs": "None",
      "pcie_generation": "4.0 x8",
      "tdp_w": 150,
      "price_usd": null,
      "price_rmb": null,
      "release_year": 2021,
      "mig_support": "No",
      "transformer_engine": "No",
      "notes": "Improved successor to K100; 2× performance; used in Baidu cloud services."
    },
    {
      "name": "Huawei Ascend 910B",
      "vendor": "Huawei",
      "architecture": "Da Vinci (Ascend 910B)",
      "process_node": "TSMC 7 nm / SMIC N+1",
      "cuda_cores": "Not applicable (Da Vinci cores)",
      "tensor_cores": "32 Da Vinci Max cores",
      "rt_cores": "None",
      "fp32_tflops": 67,
      "fp16_tflops": 320,
      "int8_tops": 512,
      "memory_gb": 64,
      "memory_type": "HBM2e",
      "memory_bandwidth_tbps": 1.2,
      "nvlink_bandwidth_gbs": "HCCS 392 GB/s",
      "pcie_generation": "4.0",
      "tdp_w": "350 - 400",
      "price_usd": null,
      "price_rmb": null,
      "release_year": 2022,
      "mig_support": "Yes (similar functionality)",
      "transformer_engine": "No",
      "notes": "Flagship AI processor; improved over 910A; deployed in Ascend Atlas 900 clusters."
    }
  ],
  "metadata": {
    "enhanced_date": "2025-01-15",
    "enhanced_by": "AI Assistant",
    "enhancement_summary": "Added critical missing specifications including: CUDA cores, Tensor cores, RT cores, release years, MIG support, Transformer Engine support, memory bandwidth specifications, PCIe generations, and interconnection bandwidth details. These additions provide comprehensive technical comparison capabilities and better reflect modern GPU architecture complexity.",
    "missing_specifications_added": [
      "CUDA cores count",
      "Tensor cores generation and count", 
      "RT cores generation and count",
      "Release year",
      "MIG (Multi-Instance GPU) support",
      "Transformer Engine support",
      "Memory bandwidth (TB/s)",
      "Interconnect bandwidth (GB/s)",
      "PCIe generation and lanes"
    ]
  }
}
{
  "gpus": [
    {
      "name": "NVIDIA A100",
      "vendor": "NVIDIA",
      "logo_path": "resources/nvidia.png",
      "architecture": "Ampere (GA100)",
      "process_node": "TSMC 7 nm",
      "cuda_cores": 6912,
      "tensor_cores": "3rd Gen (312)",
      "rt_cores": "None",
      "fp32_tflops": 19.5,
      "fp16_tflops": 312,
      "int8_tops": 624,
      "memory_gb": "40 / 80",
      "memory_type": "HBM2e",
      "memory_bandwidth_tbps": 2.0,
      "nvlink_bandwidth_gbs": 600,
      "pcie_generation": "4.0",
      "tdp_w": "250 (PCIe) / 400 (SXM4)",
      "price_usd": 30000,
      "price_rmb": 210000,
      "release_year": 2020,
      "mig_support": "Yes (up to 7 instances)",
      "transformer_engine": "No",
      "notes": "FP16/INT8 values include sparsity; up to 7 MIG instances; NVLink Gen3 600 GB/s."
    },
    {
      "name": "NVIDIA V100 32GB",
      "vendor": "NVIDIA",
      "logo_path": "resources/nvidia.png",
      "architecture": "Volta (GV100)",
      "process_node": "TSMC 12 nm",
      "cuda_cores": 5120,
      "tensor_cores": "1st Gen (640)",
      "rt_cores": "None",
      "fp32_tflops": 14,
      "fp16_tflops": 112,
      "int8_tops": 224,
      "memory_gb": 32,
      "memory_type": "HBM2",
      "memory_bandwidth_tbps": 0.9,
      "nvlink_bandwidth_gbs": 300,
      "pcie_generation": "3.0",
      "tdp_w": "250 (PCIe) / 300 (SXM2)",
      "price_usd": 8000,
      "price_rmb": 56000,
      "release_year": 2017,
      "mig_support": "No",
      "transformer_engine": "No",
      "notes": "Volta architecture; 32GB HBM2; NVLink 2.0 up to 300 GB/s."
    },
    {
      "name": "NVIDIA H100",
      "vendor": "NVIDIA",
      "logo_path": "resources/nvidia.png",
      "architecture": "Hopper (GH100) with Transformer Engine",
      "process_node": "TSMC 4N (5 nm class)",
      "cuda_cores": 16896,
      "tensor_cores": "4th Gen (528)",
      "rt_cores": "None",
      "fp32_tflops": 67,
      "fp16_tflops": 1979,
      "int8_tops": 3958,
      "memory_gb": 80,
      "memory_type": "HBM3 (SXM) / HBM2e (PCIe)",
      "memory_bandwidth_tbps": 3.35,
      "nvlink_bandwidth_gbs": 900,
      "pcie_generation": "5.0",
      "tdp_w": "350-400 (PCIe) / 700 (SXM5)",
      "price_usd": "25000 - 40000",
      "price_rmb": null,
      "release_year": 2022,
      "mig_support": "Yes (up to 7 instances)",
      "transformer_engine": "Yes (with FP8 support)",
      "notes": "NVLink Gen4 (900 GB/s), Transformer Engine with FP8 support, 528 Tensor Cores."
    },
    {
      "name": "NVIDIA H200",
      "vendor": "NVIDIA",
      "logo_path": "resources/nvidia.png",
      "architecture": "Hopper (GH100/Hopper 2)",
      "process_node": "TSMC 4N (5 nm class)",
      "cuda_cores": 16896,
      "tensor_cores": "4th Gen (Enhanced)",
      "rt_cores": "None",
      "fp32_tflops": 67,
      "fp16_tflops": 1979,
      "int8_tops": 3958,
      "memory_gb": 141,
      "memory_type": "HBM3e",
      "memory_bandwidth_tbps": 4.8,
      "nvlink_bandwidth_gbs": 900,
      "pcie_generation": "5.0",
      "tdp_w": 700,
      "price_usd": 40000,
      "price_rmb": null,
      "release_year": 2024,
      "mig_support": "Yes (up to 7 instances, 16.5GB each)",
      "transformer_engine": "Yes (Enhanced FP8)",
      "notes": "2x faster LLM inference vs H100, improved energy efficiency, NVLink4 900 GB/s."
    },
    {
      "name": "NVIDIA H20",
      "vendor": "NVIDIA",
      "logo_path": "resources/nvidia.png",
      "architecture": "Hopper (China-compliant)",
      "process_node": "TSMC 4N (5 nm class)",
      "cuda_cores": 16896,
      "tensor_cores": "4th Gen (Restricted)",
      "rt_cores": "None",
      "fp32_tflops": 44,
      "fp16_tflops": 148,
      "int8_tops": 296,
      "memory_gb": 96,
      "memory_type": "HBM3",
      "memory_bandwidth_tbps": 4.0,
      "nvlink_bandwidth_gbs": 400,
      "pcie_generation": "5.0",
      "tdp_w": 400,
      "price_usd": 12000,
      "price_rmb": 84000,
      "release_year": 2024,
      "mig_support": "Yes",
      "transformer_engine": "Yes (Limited)",
      "notes": "Designed for China market; lower interconnect bandwidth to meet export limits."
    },
    {
      "name": "NVIDIA L40S",
      "vendor": "NVIDIA",
      "logo_path": "resources/nvidia.png",
      "architecture": "Ada Lovelace (AD102)",
      "process_node": "TSMC 5 nm",
      "cuda_cores": 18176,
      "tensor_cores": "4th Gen (568)",
      "rt_cores": "3rd Gen (142)",
      "fp32_tflops": 91.6,
      "fp16_tflops": 183.2,
      "int8_tops": 734.4,
      "memory_gb": 48,
      "memory_type": "GDDR6 ECC",
      "memory_bandwidth_tbps": 0.864,
      "nvlink_bandwidth_gbs": "None",
      "pcie_generation": "4.0",
      "tdp_w": 350,
      "price_usd": null,
      "price_rmb": null,
      "release_year": 2023,
      "mig_support": "No",
      "transformer_engine": "No",
      "notes": "No NVLink; PCIe Gen4; optimized for generative AI and RTX workloads."
    },
    {
      "name": "Biren BR100",
      "vendor": "Biren Technology",
      "logo_path": null,
      "architecture": "Bilin (BR100) MCM dual-die",
      "process_node": "TSMC 7 nm",
      "cuda_cores": "Not disclosed",
      "tensor_cores": "Proprietary T-cores",
      "rt_cores": "None",
      "fp32_tflops_vendor_peak": 256,
      "fp32_tflops_measured": 16,
      "fp16_tflops": 1024,
      "int8_tops": 2048,
      "memory_gb": 64,
      "memory_type": "HBM2e",
      "memory_bandwidth_tbps": 2.3,
      "nvlink_bandwidth_gbs": "B-Link 448 GB/s",
      "pcie_generation": "5.0 with CXL",
      "tdp_w": 550,
      "price_usd": null,
      "price_rmb": null,
      "release_year": 2022,
      "mig_support": "Yes (SVI - Secure Virtual Instance)",
      "transformer_engine": "No",
      "notes": "Dual-die (77B transistors total); proprietary B-Link interconnect (2.3 TB/s); 300 MB cache; claimed 2.6× A100 performance."
    },
    {
      "name": "Alibaba Pingtouge PPU",
      "vendor": "Alibaba Group (Pingtouge)",
      "logo_path": "resources/alibaba.png",
      "architecture": "PPU Gen1",
      "process_node": "Domestic 7 nm (SMIC)",
      "cuda_cores": "Not disclosed",
      "tensor_cores": "Proprietary",
      "rt_cores": "None",
      "fp32_tflops": 120,
      "fp16_tflops": null,
      "int8_tops": 200,
      "memory_gb": 96,
      "memory_type": "HBM2e",
      "memory_bandwidth_tbps": 0.7,
      "nvlink_bandwidth_gbs": "Inter-chip 700 GB/s",
      "pcie_generation": "5.0 x15",
      "tdp_w": 400,
      "price_usd": null,
      "price_rmb": null,
      "release_year": 2024,
      "mig_support": "Unknown",
      "transformer_engine": "No",
      "notes": "700 GB/s inter-chip link; deployed at Alibaba Cloud (16,384 cards); competitive with NVIDIA H20."
    },
    {
      "name": "Baidu Kunlunxin K100",
      "vendor": "Baidu",
      "logo_path": "resources/baidu.png",
      "architecture": "Kunlunxin 1st Gen XPU-K",
      "process_node": "Samsung 14 nm",
      "cuda_cores": "Not disclosed",
      "tensor_cores": "Proprietary XPU cores",
      "rt_cores": "None",
      "fp32_tflops": 8,
      "fp16_tflops": 32,
      "int8_tops": 128,
      "memory_gb": 8,
      "memory_type": "HBM",
      "memory_bandwidth_tbps": 0.512,
      "nvlink_bandwidth_gbs": "None",
      "pcie_generation": "4.0 x8",
      "tdp_w": 75,
      "price_usd": null,
      "price_rmb": null,
      "release_year": 2018,
      "mig_support": "No",
      "transformer_engine": "No",
      "notes": "Edge-oriented AI accelerator; compact design; used for inference workloads."
    },
    {
      "name": "Baidu Kunlunxin K200",
      "vendor": "Baidu",
      "logo_path": "resources/baidu.png",
      "architecture": "Kunlunxin Gen1 XPU",
      "process_node": "Samsung 14 nm",
      "cuda_cores": "Not disclosed",
      "tensor_cores": "Proprietary XPU cores",
      "rt_cores": "None",
      "fp32_tflops": 16,
      "fp16_tflops": 64,
      "int8_tops": 256,
      "memory_gb": 16,
      "memory_type": "HBM2e",
      "memory_bandwidth_tbps": 0.512,
      "nvlink_bandwidth_gbs": "None",
      "pcie_generation": "4.0 x8",
      "tdp_w": 150,
      "price_usd": null,
      "price_rmb": null,
      "release_year": 2021,
      "mig_support": "No",
      "transformer_engine": "No",
      "notes": "Improved successor to K100; 2× performance; used in Baidu cloud services."
    },
    {
      "name": "Huawei Ascend 910B",
      "vendor": "Huawei",
      "logo_path": "resources/huawei.png",
      "architecture": "Da Vinci (Ascend 910B)",
      "process_node": "TSMC 7 nm / SMIC N+1",
      "cuda_cores": "Not applicable (Da Vinci cores)",
      "tensor_cores": "32 Da Vinci Max cores",
      "rt_cores": "None",
      "fp32_tflops": 67,
      "fp16_tflops": 320,
      "int8_tops": 512,
      "memory_gb": 64,
      "memory_type": "HBM2e",
      "memory_bandwidth_tbps": 1.2,
      "nvlink_bandwidth_gbs": "HCCS 392 GB/s",
      "pcie_generation": "4.0",
      "tdp_w": "350 - 400",
      "price_usd": null,
      "price_rmb": null,
      "release_year": 2022,
      "mig_support": "Yes (similar functionality)",
      "transformer_engine": "No",
      "notes": "Flagship AI processor; improved over 910A; deployed in Ascend Atlas 900 clusters."
    },
    {
      "name": "NVIDIA RTX 3090",
      "vendor": "NVIDIA",
      "logo_path": "resources/nvidia.png",
      "architecture": "Ampere (GA102)",
      "process_node": "Samsung 8 nm",
      "memory_gb": 24,
      "memory_type": "GDDR6X",
      "memory_bandwidth_tbps": 0.936,
      "pcie_generation": "4.0",
      "release_year": 2020,
      "notes": "Consumer flagship Ampere; 24GB GDDR6X; ~936 GB/s bandwidth."
    },
    {
      "name": "NVIDIA RTX 4090",
      "vendor": "NVIDIA",
      "logo_path": "resources/nvidia.png",
      "architecture": "Ada Lovelace (AD102)",
      "process_node": "TSMC 4N",
      "memory_gb": 24,
      "memory_type": "GDDR6X",
      "memory_bandwidth_tbps": 1.008,
      "pcie_generation": "4.0",
      "release_year": 2022,
      "notes": "Consumer flagship Ada; 24GB GDDR6X; ~1008 GB/s bandwidth."
    },
    {
      "name": "NVIDIA RTX 5090",
      "vendor": "NVIDIA",
      "logo_path": "resources/nvidia.png",
      "architecture": "Blackwell (GB202, consumer)",
      "process_node": "TSMC 3/4N class",
      "memory_gb": 32,
      "memory_type": "GDDR7",
      "memory_bandwidth_tbps": 1.792,
      "pcie_generation": "5.0",
      "release_year": 2025,
      "notes": "Projected consumer Blackwell; 32GB GDDR7; ~1.79 TB/s bandwidth."
    },
    {
      "name": "NVIDIA T4",
      "vendor": "NVIDIA",
      "logo_path": "resources/nvidia.png",
      "architecture": "Turing (TU104)",
      "process_node": "TSMC 12 nm",
      "memory_gb": 16,
      "memory_type": "GDDR6",
      "memory_bandwidth_tbps": 0.300,
      "pcie_generation": "3.0",
      "release_year": 2018,
      "notes": "Datacenter inference GPU; 16GB GDDR6; ~300 GB/s bandwidth."
    },
    {
      "name": "NVIDIA L4",
      "vendor": "NVIDIA",
      "logo_path": "resources/nvidia.png",
      "architecture": "Ada Lovelace (AD104)",
      "process_node": "TSMC 4N",
      "memory_gb": 24,
      "memory_type": "GDDR6",
      "memory_bandwidth_tbps": 0.300,
      "pcie_generation": "4.0",
      "release_year": 2023,
      "notes": "Low-profile datacenter GPU; 24GB GDDR6; ~300 GB/s bandwidth."
    },
    {
      "name": "NVIDIA Quadro RTX 6000",
      "vendor": "NVIDIA",
      "logo_path": "resources/nvidia.png",
      "architecture": "Turing (TU102)",
      "process_node": "TSMC 12 nm",
      "memory_gb": 24,
      "memory_type": "GDDR6",
      "memory_bandwidth_tbps": 0.672,
      "pcie_generation": "3.0",
      "release_year": 2018,
      "notes": "Professional Turing; 24GB GDDR6; ~672 GB/s bandwidth."
    },
    {
      "name": "NVIDIA RTX A6000",
      "vendor": "NVIDIA",
      "logo_path": "resources/nvidia.png",
      "architecture": "Ampere (GA102)",
      "process_node": "Samsung 8 nm",
      "memory_gb": 48,
      "memory_type": "GDDR6 (ECC)",
      "memory_bandwidth_tbps": 0.768,
      "pcie_generation": "4.0",
      "release_year": 2020,
      "notes": "Professional Ampere; 48GB GDDR6 (ECC); ~768 GB/s bandwidth."
    },
    {
      "name": "NVIDIA RTX 3060",
      "vendor": "NVIDIA",
      "logo_path": "resources/nvidia.png",
      "architecture": "Ampere (GA106)",
      "process_node": "Samsung 8 nm",
      "memory_gb": 12,
      "memory_type": "GDDR6",
      "memory_bandwidth_tbps": 0.360,
      "pcie_generation": "4.0",
      "release_year": 2021,
      "notes": "Consumer Ampere; 12GB GDDR6; ~360 GB/s bandwidth."
    },
    {
      "name": "NVIDIA RTX 3070",
      "vendor": "NVIDIA",
      "logo_path": "resources/nvidia.png",
      "architecture": "Ampere (GA104)",
      "process_node": "Samsung 8 nm",
      "memory_gb": 8,
      "memory_type": "GDDR6",
      "memory_bandwidth_tbps": 0.448,
      "pcie_generation": "4.0",
      "release_year": 2020,
      "notes": "Consumer Ampere; 8GB GDDR6; ~448 GB/s bandwidth."
    },
    {
      "name": "NVIDIA RTX 3080",
      "vendor": "NVIDIA",
      "logo_path": "resources/nvidia.png",
      "architecture": "Ampere (GA102)",
      "process_node": "Samsung 8 nm",
      "memory_gb": 10,
      "memory_type": "GDDR6X",
      "memory_bandwidth_tbps": 0.760,
      "pcie_generation": "4.0",
      "release_year": 2020,
      "notes": "Consumer Ampere; 10GB GDDR6X; ~760 GB/s bandwidth."
    },
    {
      "name": "NVIDIA RTX 4060",
      "vendor": "NVIDIA",
      "logo_path": "resources/nvidia.png",
      "architecture": "Ada Lovelace (AD107)",
      "process_node": "TSMC 4N",
      "memory_gb": 8,
      "memory_type": "GDDR6",
      "memory_bandwidth_tbps": 0.272,
      "pcie_generation": "4.0",
      "release_year": 2023,
      "notes": "Consumer Ada; 8GB GDDR6; ~272 GB/s bandwidth."
    },
    {
      "name": "NVIDIA RTX 4070",
      "vendor": "NVIDIA",
      "logo_path": "resources/nvidia.png",
      "architecture": "Ada Lovelace (AD104)",
      "process_node": "TSMC 4N",
      "memory_gb": 12,
      "memory_type": "GDDR6X",
      "memory_bandwidth_tbps": 0.504,
      "pcie_generation": "4.0",
      "release_year": 2023,
      "notes": "Consumer Ada; 12GB GDDR6X; ~504 GB/s bandwidth."
    },
    {
      "name": "NVIDIA RTX 4080",
      "vendor": "NVIDIA",
      "logo_path": "resources/nvidia.png",
      "architecture": "Ada Lovelace (AD103)",
      "process_node": "TSMC 4N",
      "memory_gb": 16,
      "memory_type": "GDDR6X",
      "memory_bandwidth_tbps": 0.717,
      "pcie_generation": "4.0",
      "release_year": 2022,
      "notes": "Consumer Ada; 16GB GDDR6X; ~716.8 GB/s bandwidth."
    },
    {
      "name": "NVIDIA RTX 5060",
      "vendor": "NVIDIA",
      "logo_path": "resources/nvidia.png",
      "architecture": "Blackwell (consumer, projected)",
      "process_node": "TSMC advanced",
      "memory_gb": 12,
      "memory_type": "GDDR7",
      "memory_bandwidth_tbps": 0.576,
      "pcie_generation": "5.0",
      "release_year": 2025,
      "notes": "Preliminary placeholder; 12GB GDDR7, ~576 GB/s (est.)."
    },
    {
      "name": "NVIDIA RTX 5070",
      "vendor": "NVIDIA",
      "logo_path": "resources/nvidia.png",
      "architecture": "Blackwell (consumer, projected)",
      "process_node": "TSMC advanced",
      "memory_gb": 16,
      "memory_type": "GDDR7",
      "memory_bandwidth_tbps": 0.768,
      "pcie_generation": "5.0",
      "release_year": 2025,
      "notes": "Preliminary placeholder; 16GB GDDR7, ~768 GB/s (est.)."
    },
    {
      "name": "NVIDIA RTX 5080",
      "vendor": "NVIDIA",
      "logo_path": "resources/nvidia.png",
      "architecture": "Blackwell (consumer, projected)",
      "process_node": "TSMC advanced",
      "memory_gb": 16,
      "memory_type": "GDDR7",
      "memory_bandwidth_tbps": 0.896,
      "pcie_generation": "5.0",
      "release_year": 2025,
      "notes": "Preliminary placeholder; 16GB GDDR7, ~896 GB/s (est.)."
    }
  ],
  "metadata": {
    "enhanced_date": "2025-01-15",
    "enhanced_by": "AI Assistant",
    "enhancement_summary": "Added critical missing specifications including: CUDA cores, Tensor cores, RT cores, release years, MIG support, Transformer Engine support, memory bandwidth specifications, PCIe generations, and interconnection bandwidth details. These additions provide comprehensive technical comparison capabilities and better reflect modern GPU architecture complexity.",
    "missing_specifications_added": [
      "CUDA cores count",
      "Tensor cores generation and count",
      "RT cores generation and count",
      "Release year",
      "MIG (Multi-Instance GPU) support",
      "Transformer Engine support",
      "Memory bandwidth (TB/s)",
      "Interconnect bandwidth (GB/s)",
      "PCIe generation and lanes"
    ]
  }
}